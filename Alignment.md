# 大模型对齐

来个飞书文档吧, 非常有意思的课堂. https://swze06osuex.feishu.cn/docx/FUojdTrkvoWmOlxbkB4cgKE2nrc


一句话说清楚知识蒸馏:


![20250414180625](https://s2.loli.net/2025/04/14/MLTYycAo2OHzsFi.png)

典型例子是弱智吧的数据, 使用 gpt4 生成的答案. 

Long is more for alignment. 选训练资料就选最长的. 

- 问题从哪里来呢? Non-instructuional Fine-tuning 发现问题是什么根本不重要...  实验设置挺有意思的. 

self-alignment 或许是可以成功的!